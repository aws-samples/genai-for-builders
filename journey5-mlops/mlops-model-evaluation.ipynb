{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd4cbe6-a20b-457f-a019-aae403938c0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Journey 5: Orchestrate with MLOps\n",
    "\n",
    "After completing Journey 1-4, Kaitlin has identified the right model to use for her application, and customized the model to produce accurate text summaries. \n",
    "In the future, Kaitlin would prefer not to go through the entire journey again, one step at a time, when a new FM is available in Jumpstart or a new fine-tuning dataset is available. \n",
    "She instead wants to codify her journey into a repeatable end-to-end ML workflow that can be executed later either as a user-initiated or an event-triggered workflow.    \n",
    "  \n",
    "The goal of this notebook is to provide an implementation of a multi-step SageMaker pipeline that will take care of multiple models evaluation, selection and registration into the SageMaker model registry.  \n",
    "For running this example we will use **LLama-2-7b** models that will be used with default weights or after a finetuning. All the models will be instantiated and finetuned by using [Amazon Sagemaker Jumpstart SDK](https://aws.amazon.com/sagemaker/jumpstart/).  \n",
    "\n",
    "This notebook is also using other Amazon SageMaker components:  \n",
    "\n",
    "[SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/) is a purpose-built workflow orchestration service to automate all phases of machine learning (ML) from data pre-processing to model monitoring. With an intuitive UI and Python SDK you can manage repeatable end-to-end ML pipelines at scale. The native integration with multiple AWS services allows you to customize the ML lifecycle based on your MLOps requirements.\n",
    "SageMaker Model Registry\n",
    "\n",
    "[Amazon SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html) is a purpose-built metadata store to manage the entire lifecycle of ML models from training to inference. Whether you prefer to store your model artifacts (model framework files, container image) in AWS (Amazon ECR) or outside of AWS in any third party Docker repository, you can now track them all in Amazon SageMaker Model Registry. You also have the flexibility to register a model without read/write permissions to the associated container image. If you want to track an ML model in a private repository, set the optional ‘SkipModelValidation’ parameter to ‘All’ at the time of registration. Later you can also deploy these models for inference in Amazon SageMaker.\n",
    "\n",
    "[Amazon SageMaker Clarify](https://aws.amazon.com/sagemaker/clarify/) provides purpose-built tools to gain greater insights into your ML models and data, based on metrics such as accuracy, robustness, toxicity, and bias to improve model quality and support responsible AI initiative. With the rise of generative AI, data scientists and ML engineers can leverage publicly available foundation models (FMs) to accelerate speed-to-market. To remove the heavy lifting of evaluating and selecting the right FM for your use case, Amazon SageMaker Clarify supports FM evaluation to help you quickly evaluate, compare, and select the best FM for your use case based on a variety of criteria across different tasks within minutes. It allows you to adopt FMs faster and with confidence.\n",
    "To perform evaluation we are using the open source library [FMEval](https://github.com/aws/fmeval) that empowers SageMaker Clarify FM model evaluation.\n",
    "\n",
    "This example was built by following the best practices explained in the blog post [Operationalize LLM Evaluation at Scale using Amazon SageMaker Clarify and MLOps services](https://aws.amazon.com/blogs/machine-learning/operationalize-llm-evaluation-at-scale-using-amazon-sagemaker-clarify-and-mlops-services/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342165dc-1709-456a-ad8f-ec7a5a6e2c05",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Environment setup\n",
    "You need to select `Data Science 3.0 kernel` with `ml.t3.medium` instance to run this notebook.\n",
    "\n",
    "First we need to install required dependencies and import required libraries.  \n",
    "We also make sagemaker SDK aware of the configuration file *config.yml*. \n",
    "This file *config.yml* contains general pipeline parameters like the default pipeline container instance type and the path to the file *dependencies.txt* with the required dependencies.\n",
    "These dependencies will be automatically downloaded from the pipeline container at the start of each pipeline step. We will create *requirements.txt* file later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "971e8e6ca28a3752",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-07T14:02:21.342512Z",
     "start_time": "2024-02-07T13:55:25.215197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fmeval==0.3.0\r\n",
      "  Using cached fmeval-0.3.0-py3-none-any.whl.metadata (5.7 kB)\r\n",
      "Collecting IPython (from fmeval==0.3.0)\r\n",
      "  Downloading ipython-8.21.0-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Collecting bert-score<0.4.0,>=0.3.13 (from fmeval==0.3.0)\r\n",
      "  Using cached bert_score-0.3.13-py3-none-any.whl (61 kB)\r\n",
      "Collecting detoxify<0.6.0,>=0.5.1 (from fmeval==0.3.0)\r\n",
      "  Downloading detoxify-0.5.2-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting evaluate<0.5.0,>=0.4.0 (from fmeval==0.3.0)\r\n",
      "  Using cached evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Collecting ipykernel<7.0.0,>=6.26.0 (from fmeval==0.3.0)\r\n",
      "  Downloading ipykernel-6.29.2-py3-none-any.whl.metadata (6.0 kB)\r\n",
      "Collecting jiwer<4.0.0,>=3.0.3 (from fmeval==0.3.0)\r\n",
      "  Using cached jiwer-3.0.3-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Collecting markdown (from fmeval==0.3.0)\r\n",
      "  Using cached Markdown-3.5.2-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Collecting matplotlib<4.0.0,>=3.8.0 (from fmeval==0.3.0)\r\n",
      "  Using cached matplotlib-3.8.2-cp310-cp310-macosx_10_12_x86_64.whl.metadata (5.8 kB)\r\n",
      "Collecting mypy-boto3-bedrock<2.0.0,>=1.33.2 (from fmeval==0.3.0)\r\n",
      "  Using cached mypy_boto3_bedrock-1.34.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from fmeval==0.3.0)\r\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\r\n",
      "Collecting pandas (from fmeval==0.3.0)\r\n",
      "  Downloading pandas-2.2.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (19 kB)\r\n",
      "Collecting pyarrow (from fmeval==0.3.0)\r\n",
      "  Downloading pyarrow-15.0.0-cp310-cp310-macosx_10_15_x86_64.whl.metadata (3.0 kB)\r\n",
      "Collecting pyfunctional==1.4.3 (from fmeval==0.3.0)\r\n",
      "  Using cached PyFunctional-1.4.3-py3-none-any.whl (49 kB)\r\n",
      "Collecting ray==2.7.1 (from fmeval==0.3.0)\r\n",
      "  Using cached ray-2.7.1-cp310-cp310-macosx_10_15_x86_64.whl.metadata (13 kB)\r\n",
      "Collecting rouge-score<0.2.0,>=0.1.2 (from fmeval==0.3.0)\r\n",
      "  Using cached rouge_score-0.1.2-py3-none-any.whl\r\n",
      "Collecting sagemaker<3.0.0,>=2.199.0 (from fmeval==0.3.0)\r\n",
      "  Downloading sagemaker-2.207.1-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting scikit-learn<2.0.0,>=1.3.1 (from fmeval==0.3.0)\r\n",
      "  Downloading scikit_learn-1.4.0-1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting semantic-version==2.10.0 (from fmeval==0.3.0)\r\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\r\n",
      "Collecting testbook<0.5.0,>=0.4.2 (from fmeval==0.3.0)\r\n",
      "  Using cached testbook-0.4.2-py3-none-any.whl (11 kB)\r\n",
      "Collecting torch!=2.0.1,!=2.1.0,>=2.0.0 (from fmeval==0.3.0)\r\n",
      "  Downloading torch-2.2.0-cp310-none-macosx_10_9_x86_64.whl.metadata (25 kB)\r\n",
      "Collecting transformers==4.22.1 (from fmeval==0.3.0)\r\n",
      "  Using cached transformers-4.22.1-py3-none-any.whl (4.9 MB)\r\n",
      "Collecting urllib3==1.26.18 (from fmeval==0.3.0)\r\n",
      "  Using cached urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\r\n",
      "Collecting dill>=0.2.5 (from pyfunctional==1.4.3->fmeval==0.3.0)\r\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting tabulate<=1.0.0 (from pyfunctional==1.4.3->fmeval==0.3.0)\r\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\r\n",
      "Collecting click>=7.0 (from ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting filelock (from ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting jsonschema (from ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\r\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Using cached msgpack-1.0.7-cp310-cp310-macosx_10_9_x86_64.whl.metadata (9.1 kB)\r\n",
      "Collecting packaging (from ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting protobuf!=3.19.5,>=3.15.3 (from ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Using cached protobuf-4.25.2-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\r\n",
      "Collecting pyyaml (from ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.1 kB)\r\n",
      "Collecting aiosignal (from ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\n",
      "Collecting frozenlist (from ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting requests (from ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting numpy>=1.19.3 (from ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Downloading numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata (61 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.1/61.1 kB\u001B[0m \u001B[31m559.1 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting huggingface-hub<1.0,>=0.9.0 (from transformers==4.22.1->fmeval==0.3.0)\r\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting regex!=2019.12.17 (from transformers==4.22.1->fmeval==0.3.0)\r\n",
      "  Using cached regex-2023.12.25-cp310-cp310-macosx_10_9_x86_64.whl.metadata (40 kB)\r\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.22.1->fmeval==0.3.0)\r\n",
      "  Using cached tokenizers-0.12.1-cp310-cp310-macosx_10_11_x86_64.whl (3.6 MB)\r\n",
      "Collecting tqdm>=4.27 (from transformers==4.22.1->fmeval==0.3.0)\r\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\r\n",
      "Collecting sentencepiece>=0.1.94 (from detoxify<0.6.0,>=0.5.1->fmeval==0.3.0)\r\n",
      "  Using cached sentencepiece-0.1.99-cp310-cp310-macosx_10_9_x86_64.whl (1.2 MB)\r\n",
      "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->fmeval==0.3.0)\r\n",
      "  Using cached datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->fmeval==0.3.0)\r\n",
      "  Using cached xxhash-3.4.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->fmeval==0.3.0)\r\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->fmeval==0.3.0)\r\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting responses<0.19 (from evaluate<0.5.0,>=0.4.0->fmeval==0.3.0)\r\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\r\n",
      "Collecting appnope (from ipykernel<7.0.0,>=6.26.0->fmeval==0.3.0)\r\n",
      "  Downloading appnope-0.1.4-py2.py3-none-any.whl.metadata (908 bytes)\r\n",
      "Collecting comm>=0.1.1 (from ipykernel<7.0.0,>=6.26.0->fmeval==0.3.0)\r\n",
      "  Using cached comm-0.2.1-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Collecting debugpy>=1.6.5 (from ipykernel<7.0.0,>=6.26.0->fmeval==0.3.0)\r\n",
      "  Using cached debugpy-1.8.0-py2.py3-none-any.whl.metadata (1.1 kB)\r\n",
      "Collecting jupyter-client>=6.1.12 (from ipykernel<7.0.0,>=6.26.0->fmeval==0.3.0)\r\n",
      "  Using cached jupyter_client-8.6.0-py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel<7.0.0,>=6.26.0->fmeval==0.3.0)\r\n",
      "  Using cached jupyter_core-5.7.1-py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Collecting matplotlib-inline>=0.1 (from ipykernel<7.0.0,>=6.26.0->fmeval==0.3.0)\r\n",
      "  Using cached matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\r\n",
      "Collecting nest-asyncio (from ipykernel<7.0.0,>=6.26.0->fmeval==0.3.0)\r\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting psutil (from ipykernel<7.0.0,>=6.26.0->fmeval==0.3.0)\r\n",
      "  Downloading psutil-5.9.8-cp36-abi3-macosx_10_9_x86_64.whl.metadata (21 kB)\r\n",
      "Collecting pyzmq>=24 (from ipykernel<7.0.0,>=6.26.0->fmeval==0.3.0)\r\n",
      "  Using cached pyzmq-25.1.2-cp310-cp310-macosx_10_15_universal2.whl.metadata (4.9 kB)\r\n",
      "Collecting tornado>=6.1 (from ipykernel<7.0.0,>=6.26.0->fmeval==0.3.0)\r\n",
      "  Using cached tornado-6.4-cp38-abi3-macosx_10_9_x86_64.whl.metadata (2.5 kB)\r\n",
      "Collecting traitlets>=5.4.0 (from ipykernel<7.0.0,>=6.26.0->fmeval==0.3.0)\r\n",
      "  Using cached traitlets-5.14.1-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting decorator (from IPython->fmeval==0.3.0)\r\n",
      "  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\r\n",
      "Collecting jedi>=0.16 (from IPython->fmeval==0.3.0)\r\n",
      "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting prompt-toolkit<3.1.0,>=3.0.41 (from IPython->fmeval==0.3.0)\r\n",
      "  Using cached prompt_toolkit-3.0.43-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Collecting pygments>=2.4.0 (from IPython->fmeval==0.3.0)\r\n",
      "  Using cached pygments-2.17.2-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Collecting stack-data (from IPython->fmeval==0.3.0)\r\n",
      "  Using cached stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting exceptiongroup (from IPython->fmeval==0.3.0)\r\n",
      "  Using cached exceptiongroup-1.2.0-py3-none-any.whl.metadata (6.6 kB)\r\n",
      "Collecting pexpect>4.3 (from IPython->fmeval==0.3.0)\r\n",
      "  Using cached pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting rapidfuzz<4,>=3 (from jiwer<4.0.0,>=3.0.3->fmeval==0.3.0)\r\n",
      "  Using cached rapidfuzz-3.6.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<4.0.0,>=3.8.0->fmeval==0.3.0)\r\n",
      "  Using cached contourpy-1.2.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (5.8 kB)\r\n",
      "Collecting cycler>=0.10 (from matplotlib<4.0.0,>=3.8.0->fmeval==0.3.0)\r\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting fonttools>=4.22.0 (from matplotlib<4.0.0,>=3.8.0->fmeval==0.3.0)\r\n",
      "  Downloading fonttools-4.48.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (158 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m158.9/158.9 kB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting kiwisolver>=1.3.1 (from matplotlib<4.0.0,>=3.8.0->fmeval==0.3.0)\r\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.4 kB)\r\n",
      "Collecting pillow>=8 (from matplotlib<4.0.0,>=3.8.0->fmeval==0.3.0)\r\n",
      "  Using cached pillow-10.2.0-cp310-cp310-macosx_10_10_x86_64.whl.metadata (9.7 kB)\r\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib<4.0.0,>=3.8.0->fmeval==0.3.0)\r\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting python-dateutil>=2.7 (from matplotlib<4.0.0,>=3.8.0->fmeval==0.3.0)\r\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\r\n",
      "Collecting typing-extensions>=4.1.0 (from mypy-boto3-bedrock<2.0.0,>=1.33.2->fmeval==0.3.0)\r\n",
      "  Using cached typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting joblib (from nltk<4.0.0,>=3.8.1->fmeval==0.3.0)\r\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting pytz>=2020.1 (from pandas->fmeval==0.3.0)\r\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting tzdata>=2022.7 (from pandas->fmeval==0.3.0)\r\n",
      "  Using cached tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting absl-py (from rouge-score<0.2.0,>=0.1.2->fmeval==0.3.0)\r\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting six>=1.14.0 (from rouge-score<0.2.0,>=0.1.2->fmeval==0.3.0)\r\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Collecting attrs<24,>=23.1.0 (from sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\r\n",
      "Collecting boto3<2.0,>=1.33.3 (from sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Downloading boto3-1.34.36-py3-none-any.whl.metadata (6.6 kB)\r\n",
      "Collecting cloudpickle==2.2.1 (from sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\r\n",
      "Collecting google-pasta (from sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\r\n",
      "Collecting smdebug-rulesconfig==1.0.1 (from sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Using cached smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\r\n",
      "Collecting importlib-metadata<7.0,>=1.4.0 (from sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Using cached importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Collecting pathos (from sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Downloading pathos-0.3.2-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting schema (from sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Using cached schema-0.7.5-py2.py3-none-any.whl (17 kB)\r\n",
      "Collecting platformdirs (from sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Downloading platformdirs-4.2.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting tblib<3,>=1.7.0 (from sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Using cached tblib-2.0.0-py3-none-any.whl.metadata (25 kB)\r\n",
      "Collecting docker (from sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Using cached docker-7.0.0-py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Collecting scipy>=1.6.0 (from scikit-learn<2.0.0,>=1.3.1->fmeval==0.3.0)\r\n",
      "  Downloading scipy-1.12.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (60 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m60.4/60.4 kB\u001B[0m \u001B[31m1.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn<2.0.0,>=1.3.1->fmeval==0.3.0)\r\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\r\n",
      "Collecting nbformat>=5.0.4 (from testbook<0.5.0,>=0.4.2->fmeval==0.3.0)\r\n",
      "  Using cached nbformat-5.9.2-py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Collecting nbclient>=0.4.0 (from testbook<0.5.0,>=0.4.2->fmeval==0.3.0)\r\n",
      "  Using cached nbclient-0.9.0-py3-none-any.whl.metadata (7.8 kB)\r\n",
      "Collecting sympy (from torch!=2.0.1,!=2.1.0,>=2.0.0->fmeval==0.3.0)\r\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\r\n",
      "Collecting networkx (from torch!=2.0.1,!=2.1.0,>=2.0.0->fmeval==0.3.0)\r\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\r\n",
      "Collecting jinja2 (from torch!=2.0.1,!=2.1.0,>=2.0.0->fmeval==0.3.0)\r\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting botocore<1.35.0,>=1.34.36 (from boto3<2.0,>=1.33.3->sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Downloading botocore-1.34.36-py3-none-any.whl.metadata (5.7 kB)\r\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.33.3->sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\r\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0,>=1.33.3->sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Using cached s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Collecting pyarrow-hotfix (from datasets>=2.0.0->evaluate<0.5.0,>=0.4.0->fmeval==0.3.0)\r\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Collecting dill>=0.2.5 (from pyfunctional==1.4.3->fmeval==0.3.0)\r\n",
      "  Using cached dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\r\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->fmeval==0.3.0)\r\n",
      "  Using cached fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting aiohttp (from datasets>=2.0.0->evaluate<0.5.0,>=0.4.0->fmeval==0.3.0)\r\n",
      "  Downloading aiohttp-3.9.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (7.4 kB)\r\n",
      "Collecting zipp>=0.5 (from importlib-metadata<7.0,>=1.4.0->sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Using cached zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Collecting parso<0.9.0,>=0.8.3 (from jedi>=0.16->IPython->fmeval==0.3.0)\r\n",
      "  Using cached parso-0.8.3-py2.py3-none-any.whl (100 kB)\r\n",
      "Collecting fastjsonschema (from nbformat>=5.0.4->testbook<0.5.0,>=0.4.2->fmeval==0.3.0)\r\n",
      "  Using cached fastjsonschema-2.19.1-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting referencing>=0.28.4 (from jsonschema->ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Downloading referencing-0.33.0-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Using cached rpds_py-0.17.1-cp310-cp310-macosx_10_12_x86_64.whl.metadata (4.1 kB)\r\n",
      "Collecting ptyprocess>=0.5 (from pexpect>4.3->IPython->fmeval==0.3.0)\r\n",
      "  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\r\n",
      "Collecting wcwidth (from prompt-toolkit<3.1.0,>=3.0.41->IPython->fmeval==0.3.0)\r\n",
      "  Using cached wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting charset-normalizer<4,>=2 (from requests->ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (33 kB)\r\n",
      "Collecting idna<4,>=2.5 (from requests->ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\r\n",
      "Collecting certifi>=2017.4.17 (from requests->ray==2.7.1->fmeval==0.3.0)\r\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch!=2.0.1,!=2.1.0,>=2.0.0->fmeval==0.3.0)\r\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata (3.0 kB)\r\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->fmeval==0.3.0)\r\n",
      "  Using cached multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting ppft>=1.7.6.8 (from pathos->sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Downloading ppft-1.7.6.8-py3-none-any.whl.metadata (12 kB)\r\n",
      "INFO: pip is looking at multiple versions of pathos to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting pathos (from sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Using cached pathos-0.3.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting pox>=0.3.3 (from pathos->sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Downloading pox-0.3.4-py3-none-any.whl.metadata (8.0 kB)\r\n",
      "Collecting contextlib2>=0.5.5 (from schema->sagemaker<3.0.0,>=2.199.0->fmeval==0.3.0)\r\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\r\n",
      "Collecting executing>=1.2.0 (from stack-data->IPython->fmeval==0.3.0)\r\n",
      "  Using cached executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\r\n",
      "Collecting asttokens>=2.1.0 (from stack-data->IPython->fmeval==0.3.0)\r\n",
      "  Using cached asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\r\n",
      "Collecting pure-eval (from stack-data->IPython->fmeval==0.3.0)\r\n",
      "  Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)\r\n",
      "Collecting mpmath>=0.19 (from sympy->torch!=2.0.1,!=2.1.0,>=2.0.0->fmeval==0.3.0)\r\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate<0.5.0,>=0.4.0->fmeval==0.3.0)\r\n",
      "  Downloading multidict-6.0.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata (4.2 kB)\r\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.0.0->evaluate<0.5.0,>=0.4.0->fmeval==0.3.0)\r\n",
      "  Using cached yarl-1.9.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata (31 kB)\r\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets>=2.0.0->evaluate<0.5.0,>=0.4.0->fmeval==0.3.0)\r\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Using cached fmeval-0.3.0-py3-none-any.whl (103 kB)\r\n",
      "Using cached ray-2.7.1-cp310-cp310-macosx_10_15_x86_64.whl (63.2 MB)\r\n",
      "Using cached urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\r\n",
      "Downloading detoxify-0.5.2-py3-none-any.whl (12 kB)\r\n",
      "Using cached evaluate-0.4.1-py3-none-any.whl (84 kB)\r\n",
      "Downloading ipykernel-6.29.2-py3-none-any.whl (116 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m116.1/116.1 kB\u001B[0m \u001B[31m1.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hDownloading ipython-8.21.0-py3-none-any.whl (810 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m810.0/810.0 kB\u001B[0m \u001B[31m1.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached jiwer-3.0.3-py3-none-any.whl (21 kB)\r\n",
      "Using cached matplotlib-3.8.2-cp310-cp310-macosx_10_12_x86_64.whl (7.6 MB)\r\n",
      "Using cached mypy_boto3_bedrock-1.34.0-py3-none-any.whl (27 kB)\r\n",
      "Downloading pandas-2.2.0-cp310-cp310-macosx_10_9_x86_64.whl (12.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.5/12.5 MB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading sagemaker-2.207.1-py3-none-any.whl (1.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.4/1.4 MB\u001B[0m \u001B[31m1.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading scikit_learn-1.4.0-1-cp310-cp310-macosx_10_9_x86_64.whl (11.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.5/11.5 MB\u001B[0m \u001B[31m1.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading torch-2.2.0-cp310-none-macosx_10_9_x86_64.whl (150.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m150.8/150.8 MB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:03\u001B[0mm\r\n",
      "\u001B[?25hUsing cached Markdown-3.5.2-py3-none-any.whl (103 kB)\r\n",
      "Downloading pyarrow-15.0.0-cp310-cp310-macosx_10_15_x86_64.whl (27.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m27.1/27.1 MB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached attrs-23.2.0-py3-none-any.whl (60 kB)\r\n",
      "Downloading boto3-1.34.36-py3-none-any.whl (139 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m139.3/139.3 kB\u001B[0m \u001B[31m896.6 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached click-8.1.7-py3-none-any.whl (97 kB)\r\n",
      "Using cached comm-0.2.1-py3-none-any.whl (7.2 kB)\r\n",
      "Using cached contourpy-1.2.0-cp310-cp310-macosx_10_9_x86_64.whl (256 kB)\r\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\r\n",
      "Using cached datasets-2.16.1-py3-none-any.whl (507 kB)\r\n",
      "Using cached debugpy-1.8.0-py2.py3-none-any.whl (5.0 MB)\r\n",
      "Using cached dill-0.3.7-py3-none-any.whl (115 kB)\r\n",
      "Downloading fonttools-4.48.1-cp310-cp310-macosx_10_9_x86_64.whl (2.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.3/2.3 MB\u001B[0m \u001B[31m1.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\r\n",
      "Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m330.1/330.1 kB\u001B[0m \u001B[31m1.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\r\n",
      "Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\r\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\r\n",
      "Using cached jupyter_client-8.6.0-py3-none-any.whl (105 kB)\r\n",
      "Using cached jupyter_core-5.7.1-py3-none-any.whl (28 kB)\r\n",
      "Using cached kiwisolver-1.4.5-cp310-cp310-macosx_10_9_x86_64.whl (68 kB)\r\n",
      "Using cached msgpack-1.0.7-cp310-cp310-macosx_10_9_x86_64.whl (234 kB)\r\n",
      "Using cached nbclient-0.9.0-py3-none-any.whl (24 kB)\r\n",
      "Using cached nbformat-5.9.2-py3-none-any.whl (77 kB)\r\n",
      "Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m85.5/85.5 kB\u001B[0m \u001B[31m1.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[?25hDownloading numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl (20.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m20.6/20.6 MB\u001B[0m \u001B[31m1.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0m:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached packaging-23.2-py3-none-any.whl (53 kB)\r\n",
      "Using cached pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\r\n",
      "Using cached pillow-10.2.0-cp310-cp310-macosx_10_10_x86_64.whl (3.5 MB)\r\n",
      "Downloading platformdirs-4.2.0-py3-none-any.whl (17 kB)\r\n",
      "Using cached prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\r\n",
      "Using cached protobuf-4.25.2-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\r\n",
      "Using cached pygments-2.17.2-py3-none-any.whl (1.2 MB)\r\n",
      "Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\r\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m505.5/505.5 kB\u001B[0m \u001B[31m1.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hUsing cached PyYAML-6.0.1-cp310-cp310-macosx_10_9_x86_64.whl (189 kB)\r\n",
      "Using cached pyzmq-25.1.2-cp310-cp310-macosx_10_15_universal2.whl (1.9 MB)\r\n",
      "Using cached rapidfuzz-3.6.1-cp310-cp310-macosx_10_9_x86_64.whl (2.8 MB)\r\n",
      "Using cached regex-2023.12.25-cp310-cp310-macosx_10_9_x86_64.whl (296 kB)\r\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\r\n",
      "Downloading scipy-1.12.0-cp310-cp310-macosx_10_9_x86_64.whl (38.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m38.9/38.9 MB\u001B[0m \u001B[31m1.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached tblib-2.0.0-py3-none-any.whl (11 kB)\r\n",
      "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\r\n",
      "Using cached tornado-6.4-cp38-abi3-macosx_10_9_x86_64.whl (431 kB)\r\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\r\n",
      "Using cached traitlets-5.14.1-py3-none-any.whl (85 kB)\r\n",
      "Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\r\n",
      "Using cached tzdata-2023.4-py2.py3-none-any.whl (346 kB)\r\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m133.7/133.7 kB\u001B[0m \u001B[31m1.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached frozenlist-1.4.1-cp310-cp310-macosx_10_9_x86_64.whl (53 kB)\r\n",
      "Downloading appnope-0.1.4-py2.py3-none-any.whl (4.3 kB)\r\n",
      "Using cached docker-7.0.0-py3-none-any.whl (147 kB)\r\n",
      "Using cached exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\r\n",
      "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\r\n",
      "Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\r\n",
      "Using cached multiprocess-0.70.15-py310-none-any.whl (134 kB)\r\n",
      "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\r\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\r\n",
      "Using cached pathos-0.3.1-py3-none-any.whl (82 kB)\r\n",
      "Downloading psutil-5.9.8-cp36-abi3-macosx_10_9_x86_64.whl (248 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m248.7/248.7 kB\u001B[0m \u001B[31m1.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached stack_data-0.6.3-py3-none-any.whl (24 kB)\r\n",
      "Using cached xxhash-3.4.1-cp310-cp310-macosx_10_9_x86_64.whl (31 kB)\r\n",
      "Downloading aiohttp-3.9.3-cp310-cp310-macosx_10_9_x86_64.whl (397 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m397.9/397.9 kB\u001B[0m \u001B[31m1.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\r\n",
      "Downloading botocore-1.34.36-py3-none-any.whl (11.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.9/11.9 MB\u001B[0m \u001B[31m1.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hDownloading certifi-2024.2.2-py3-none-any.whl (163 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m163.8/163.8 kB\u001B[0m \u001B[31m1.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached charset_normalizer-3.3.2-cp310-cp310-macosx_10_9_x86_64.whl (122 kB)\r\n",
      "Using cached executing-2.0.1-py2.py3-none-any.whl (24 kB)\r\n",
      "Using cached idna-3.6-py3-none-any.whl (61 kB)\r\n",
      "Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\r\n",
      "Downloading MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_x86_64.whl (14 kB)\r\n",
      "Downloading pox-0.3.4-py3-none-any.whl (29 kB)\r\n",
      "Downloading ppft-1.7.6.8-py3-none-any.whl (56 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.8/56.8 kB\u001B[0m \u001B[31m889.8 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading referencing-0.33.0-py3-none-any.whl (26 kB)\r\n",
      "Using cached rpds_py-0.17.1-cp310-cp310-macosx_10_12_x86_64.whl (354 kB)\r\n",
      "Using cached s3transfer-0.10.0-py3-none-any.whl (82 kB)\r\n",
      "Using cached zipp-3.17.0-py3-none-any.whl (7.4 kB)\r\n",
      "Using cached fastjsonschema-2.19.1-py3-none-any.whl (23 kB)\r\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\r\n",
      "Using cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\r\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\r\n",
      "Downloading multidict-6.0.5-cp310-cp310-macosx_10_9_x86_64.whl (30 kB)\r\n",
      "Using cached yarl-1.9.4-cp310-cp310-macosx_10_9_x86_64.whl (81 kB)\r\n",
      "Installing collected packages: wcwidth, tokenizers, sentencepiece, pytz, pure-eval, ptyprocess, mpmath, fastjsonschema, zipp, xxhash, urllib3, tzdata, typing-extensions, traitlets, tqdm, tornado, threadpoolctl, tblib, tabulate, sympy, smdebug-rulesconfig, six, semantic-version, rpds-py, regex, rapidfuzz, pyzmq, pyyaml, pyparsing, pygments, pyarrow-hotfix, psutil, protobuf, prompt-toolkit, ppft, pox, platformdirs, pillow, pexpect, parso, packaging, numpy, networkx, nest-asyncio, multidict, msgpack, MarkupSafe, markdown, kiwisolver, joblib, jmespath, idna, fsspec, frozenlist, fonttools, filelock, executing, exceptiongroup, dill, decorator, debugpy, cycler, contextlib2, cloudpickle, click, charset-normalizer, certifi, attrs, async-timeout, appnope, absl-py, yarl, scipy, schema, requests, referencing, python-dateutil, pyfunctional, pyarrow, nltk, mypy-boto3-bedrock, multiprocess, matplotlib-inline, jupyter-core, jiwer, jinja2, jedi, importlib-metadata, google-pasta, contourpy, comm, asttokens, aiosignal, torch, stack-data, scikit-learn, rouge-score, responses, pathos, pandas, matplotlib, jupyter-client, jsonschema-specifications, huggingface-hub, docker, botocore, aiohttp, transformers, s3transfer, jsonschema, IPython, ray, nbformat, ipykernel, detoxify, datasets, boto3, bert-score, sagemaker, nbclient, evaluate, testbook, fmeval\r\n",
      "  Attempting uninstall: wcwidth\r\n",
      "    Found existing installation: wcwidth 0.2.13\r\n",
      "    Uninstalling wcwidth-0.2.13:\r\n",
      "      Successfully uninstalled wcwidth-0.2.13\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.12.1\r\n",
      "    Uninstalling tokenizers-0.12.1:\r\n",
      "      Successfully uninstalled tokenizers-0.12.1\r\n",
      "  Attempting uninstall: sentencepiece\r\n",
      "    Found existing installation: sentencepiece 0.1.99\r\n",
      "    Uninstalling sentencepiece-0.1.99:\r\n",
      "      Successfully uninstalled sentencepiece-0.1.99\r\n",
      "  Attempting uninstall: pytz\r\n",
      "    Found existing installation: pytz 2023.3.post1\r\n",
      "    Uninstalling pytz-2023.3.post1:\r\n",
      "      Successfully uninstalled pytz-2023.3.post1\r\n",
      "  Attempting uninstall: pure-eval\r\n",
      "    Found existing installation: pure-eval 0.2.2\r\n",
      "    Uninstalling pure-eval-0.2.2:\r\n",
      "      Successfully uninstalled pure-eval-0.2.2\r\n",
      "  Attempting uninstall: ptyprocess\r\n",
      "    Found existing installation: ptyprocess 0.7.0\r\n",
      "    Uninstalling ptyprocess-0.7.0:\r\n",
      "      Successfully uninstalled ptyprocess-0.7.0\r\n",
      "  Attempting uninstall: mpmath\r\n",
      "    Found existing installation: mpmath 1.3.0\r\n",
      "    Uninstalling mpmath-1.3.0:\r\n",
      "      Successfully uninstalled mpmath-1.3.0\r\n",
      "  Attempting uninstall: fastjsonschema\r\n",
      "    Found existing installation: fastjsonschema 2.19.1\r\n",
      "    Uninstalling fastjsonschema-2.19.1:\r\n",
      "      Successfully uninstalled fastjsonschema-2.19.1\r\n",
      "  Attempting uninstall: zipp\r\n",
      "    Found existing installation: zipp 3.17.0\r\n",
      "    Uninstalling zipp-3.17.0:\r\n",
      "      Successfully uninstalled zipp-3.17.0\r\n",
      "  Attempting uninstall: xxhash\r\n",
      "    Found existing installation: xxhash 3.4.1\r\n",
      "    Uninstalling xxhash-3.4.1:\r\n",
      "      Successfully uninstalled xxhash-3.4.1\r\n",
      "  Attempting uninstall: urllib3\r\n",
      "    Found existing installation: urllib3 1.26.18\r\n",
      "    Uninstalling urllib3-1.26.18:\r\n",
      "      Successfully uninstalled urllib3-1.26.18\r\n",
      "  Attempting uninstall: tzdata\r\n",
      "    Found existing installation: tzdata 2023.4\r\n",
      "    Uninstalling tzdata-2023.4:\r\n",
      "      Successfully uninstalled tzdata-2023.4\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.9.0\r\n",
      "    Uninstalling typing_extensions-4.9.0:\r\n",
      "      Successfully uninstalled typing_extensions-4.9.0\r\n",
      "  Attempting uninstall: traitlets\r\n",
      "    Found existing installation: traitlets 5.14.1\r\n",
      "    Uninstalling traitlets-5.14.1:\r\n",
      "      Successfully uninstalled traitlets-5.14.1\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.66.1\r\n",
      "    Uninstalling tqdm-4.66.1:\r\n",
      "      Successfully uninstalled tqdm-4.66.1\r\n",
      "  Attempting uninstall: tornado\r\n",
      "    Found existing installation: tornado 6.4\r\n",
      "    Uninstalling tornado-6.4:\r\n",
      "      Successfully uninstalled tornado-6.4\r\n",
      "  Attempting uninstall: threadpoolctl\r\n",
      "    Found existing installation: threadpoolctl 3.2.0\r\n",
      "    Uninstalling threadpoolctl-3.2.0:\r\n",
      "      Successfully uninstalled threadpoolctl-3.2.0\r\n",
      "  Attempting uninstall: tblib\r\n",
      "    Found existing installation: tblib 2.0.0\r\n",
      "    Uninstalling tblib-2.0.0:\r\n",
      "      Successfully uninstalled tblib-2.0.0\r\n",
      "  Attempting uninstall: tabulate\r\n",
      "    Found existing installation: tabulate 0.9.0\r\n",
      "    Uninstalling tabulate-0.9.0:\r\n",
      "      Successfully uninstalled tabulate-0.9.0\r\n",
      "  Attempting uninstall: sympy\r\n",
      "    Found existing installation: sympy 1.12\r\n",
      "    Uninstalling sympy-1.12:\r\n",
      "      Successfully uninstalled sympy-1.12\r\n",
      "  Attempting uninstall: smdebug-rulesconfig\r\n",
      "    Found existing installation: smdebug-rulesconfig 1.0.1\r\n",
      "    Uninstalling smdebug-rulesconfig-1.0.1:\r\n",
      "      Successfully uninstalled smdebug-rulesconfig-1.0.1\r\n",
      "  Attempting uninstall: six\r\n",
      "    Found existing installation: six 1.16.0\r\n",
      "    Uninstalling six-1.16.0:\r\n",
      "      Successfully uninstalled six-1.16.0\r\n",
      "  Attempting uninstall: semantic-version\r\n",
      "    Found existing installation: semantic-version 2.10.0\r\n",
      "    Uninstalling semantic-version-2.10.0:\r\n",
      "      Successfully uninstalled semantic-version-2.10.0\r\n",
      "  Attempting uninstall: rpds-py\r\n",
      "    Found existing installation: rpds-py 0.17.1\r\n",
      "    Uninstalling rpds-py-0.17.1:\r\n",
      "      Successfully uninstalled rpds-py-0.17.1\r\n",
      "  Attempting uninstall: regex\r\n",
      "    Found existing installation: regex 2023.12.25\r\n",
      "    Uninstalling regex-2023.12.25:\r\n",
      "      Successfully uninstalled regex-2023.12.25\r\n",
      "  Attempting uninstall: rapidfuzz\r\n",
      "    Found existing installation: rapidfuzz 3.6.1\r\n",
      "    Uninstalling rapidfuzz-3.6.1:\r\n",
      "      Successfully uninstalled rapidfuzz-3.6.1\r\n",
      "  Attempting uninstall: pyzmq\r\n",
      "    Found existing installation: pyzmq 25.1.2\r\n",
      "    Uninstalling pyzmq-25.1.2:\r\n",
      "      Successfully uninstalled pyzmq-25.1.2\r\n",
      "  Attempting uninstall: pyyaml\r\n",
      "    Found existing installation: PyYAML 6.0.1\r\n",
      "    Uninstalling PyYAML-6.0.1:\r\n",
      "      Successfully uninstalled PyYAML-6.0.1\r\n",
      "  Attempting uninstall: pyparsing\r\n",
      "    Found existing installation: pyparsing 3.1.1\r\n",
      "    Uninstalling pyparsing-3.1.1:\r\n",
      "      Successfully uninstalled pyparsing-3.1.1\r\n",
      "  Attempting uninstall: pygments\r\n",
      "    Found existing installation: Pygments 2.17.2\r\n",
      "    Uninstalling Pygments-2.17.2:\r\n",
      "      Successfully uninstalled Pygments-2.17.2\r\n",
      "  Attempting uninstall: pyarrow-hotfix\r\n",
      "    Found existing installation: pyarrow-hotfix 0.6\r\n",
      "    Uninstalling pyarrow-hotfix-0.6:\r\n",
      "      Successfully uninstalled pyarrow-hotfix-0.6\r\n",
      "  Attempting uninstall: psutil\r\n",
      "    Found existing installation: psutil 5.9.7\r\n",
      "    Uninstalling psutil-5.9.7:\r\n",
      "      Successfully uninstalled psutil-5.9.7\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 4.25.2\r\n",
      "    Uninstalling protobuf-4.25.2:\r\n",
      "      Successfully uninstalled protobuf-4.25.2\r\n",
      "  Attempting uninstall: prompt-toolkit\r\n",
      "    Found existing installation: prompt-toolkit 3.0.43\r\n",
      "    Uninstalling prompt-toolkit-3.0.43:\r\n",
      "      Successfully uninstalled prompt-toolkit-3.0.43\r\n",
      "  Attempting uninstall: ppft\r\n",
      "    Found existing installation: ppft 1.7.6.7\r\n",
      "    Uninstalling ppft-1.7.6.7:\r\n",
      "      Successfully uninstalled ppft-1.7.6.7\r\n",
      "  Attempting uninstall: pox\r\n",
      "    Found existing installation: pox 0.3.3\r\n",
      "    Uninstalling pox-0.3.3:\r\n",
      "      Successfully uninstalled pox-0.3.3\r\n",
      "  Attempting uninstall: platformdirs\r\n",
      "    Found existing installation: platformdirs 4.1.0\r\n",
      "    Uninstalling platformdirs-4.1.0:\r\n",
      "      Successfully uninstalled platformdirs-4.1.0\r\n",
      "  Attempting uninstall: pillow\r\n",
      "    Found existing installation: pillow 10.2.0\r\n",
      "    Uninstalling pillow-10.2.0:\r\n",
      "      Successfully uninstalled pillow-10.2.0\r\n",
      "  Attempting uninstall: pexpect\r\n",
      "    Found existing installation: pexpect 4.9.0\r\n",
      "    Uninstalling pexpect-4.9.0:\r\n",
      "      Successfully uninstalled pexpect-4.9.0\r\n",
      "  Attempting uninstall: parso\r\n",
      "    Found existing installation: parso 0.8.3\r\n",
      "    Uninstalling parso-0.8.3:\r\n",
      "      Successfully uninstalled parso-0.8.3\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 23.2\r\n",
      "    Uninstalling packaging-23.2:\r\n",
      "      Successfully uninstalled packaging-23.2\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.3\r\n",
      "    Uninstalling numpy-1.26.3:\r\n",
      "      Successfully uninstalled numpy-1.26.3\r\n",
      "  Attempting uninstall: networkx\r\n",
      "    Found existing installation: networkx 3.2.1\r\n",
      "    Uninstalling networkx-3.2.1:\r\n",
      "      Successfully uninstalled networkx-3.2.1\r\n",
      "  Attempting uninstall: nest-asyncio\r\n",
      "    Found existing installation: nest-asyncio 1.5.8\r\n",
      "    Uninstalling nest-asyncio-1.5.8:\r\n",
      "      Successfully uninstalled nest-asyncio-1.5.8\r\n",
      "  Attempting uninstall: multidict\r\n",
      "    Found existing installation: multidict 6.0.4\r\n",
      "    Uninstalling multidict-6.0.4:\r\n",
      "      Successfully uninstalled multidict-6.0.4\r\n",
      "  Attempting uninstall: msgpack\r\n",
      "    Found existing installation: msgpack 1.0.7\r\n",
      "    Uninstalling msgpack-1.0.7:\r\n",
      "      Successfully uninstalled msgpack-1.0.7\r\n",
      "  Attempting uninstall: MarkupSafe\r\n",
      "    Found existing installation: MarkupSafe 2.1.3\r\n",
      "    Uninstalling MarkupSafe-2.1.3:\r\n",
      "      Successfully uninstalled MarkupSafe-2.1.3\r\n",
      "  Attempting uninstall: markdown\r\n",
      "    Found existing installation: Markdown 3.5.2\r\n",
      "    Uninstalling Markdown-3.5.2:\r\n",
      "      Successfully uninstalled Markdown-3.5.2\r\n",
      "  Attempting uninstall: kiwisolver\r\n",
      "    Found existing installation: kiwisolver 1.4.5\r\n",
      "    Uninstalling kiwisolver-1.4.5:\r\n",
      "      Successfully uninstalled kiwisolver-1.4.5\r\n",
      "  Attempting uninstall: joblib\r\n",
      "    Found existing installation: joblib 1.3.2\r\n",
      "    Uninstalling joblib-1.3.2:\r\n",
      "      Successfully uninstalled joblib-1.3.2\r\n",
      "  Attempting uninstall: jmespath\r\n",
      "    Found existing installation: jmespath 1.0.1\r\n",
      "    Uninstalling jmespath-1.0.1:\r\n",
      "      Successfully uninstalled jmespath-1.0.1\r\n",
      "  Attempting uninstall: idna\r\n",
      "    Found existing installation: idna 3.6\r\n",
      "    Uninstalling idna-3.6:\r\n",
      "      Successfully uninstalled idna-3.6\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2023.12.2\r\n",
      "    Uninstalling fsspec-2023.12.2:\r\n",
      "      Successfully uninstalled fsspec-2023.12.2\r\n",
      "  Attempting uninstall: frozenlist\r\n",
      "    Found existing installation: frozenlist 1.4.1\r\n",
      "    Uninstalling frozenlist-1.4.1:\r\n",
      "      Successfully uninstalled frozenlist-1.4.1\r\n",
      "  Attempting uninstall: fonttools\r\n",
      "    Found existing installation: fonttools 4.47.2\r\n",
      "    Uninstalling fonttools-4.47.2:\r\n",
      "      Successfully uninstalled fonttools-4.47.2\r\n",
      "  Attempting uninstall: filelock\r\n",
      "    Found existing installation: filelock 3.13.1\r\n",
      "    Uninstalling filelock-3.13.1:\r\n",
      "      Successfully uninstalled filelock-3.13.1\r\n",
      "  Attempting uninstall: executing\r\n",
      "    Found existing installation: executing 2.0.1\r\n",
      "    Uninstalling executing-2.0.1:\r\n",
      "      Successfully uninstalled executing-2.0.1\r\n",
      "  Attempting uninstall: exceptiongroup\r\n",
      "    Found existing installation: exceptiongroup 1.2.0\r\n",
      "    Uninstalling exceptiongroup-1.2.0:\r\n",
      "      Successfully uninstalled exceptiongroup-1.2.0\r\n",
      "  Attempting uninstall: dill\r\n",
      "    Found existing installation: dill 0.3.7\r\n",
      "    Uninstalling dill-0.3.7:\r\n",
      "      Successfully uninstalled dill-0.3.7\r\n",
      "  Attempting uninstall: decorator\r\n",
      "    Found existing installation: decorator 5.1.1\r\n",
      "    Uninstalling decorator-5.1.1:\r\n",
      "      Successfully uninstalled decorator-5.1.1\r\n",
      "  Attempting uninstall: debugpy\r\n",
      "    Found existing installation: debugpy 1.8.0\r\n",
      "    Uninstalling debugpy-1.8.0:\r\n",
      "      Successfully uninstalled debugpy-1.8.0\r\n",
      "  Attempting uninstall: cycler\r\n",
      "    Found existing installation: cycler 0.12.1\r\n",
      "    Uninstalling cycler-0.12.1:\r\n",
      "      Successfully uninstalled cycler-0.12.1\r\n",
      "  Attempting uninstall: contextlib2\r\n",
      "    Found existing installation: contextlib2 21.6.0\r\n",
      "    Uninstalling contextlib2-21.6.0:\r\n",
      "      Successfully uninstalled contextlib2-21.6.0\r\n",
      "  Attempting uninstall: cloudpickle\r\n",
      "    Found existing installation: cloudpickle 2.2.1\r\n",
      "    Uninstalling cloudpickle-2.2.1:\r\n",
      "      Successfully uninstalled cloudpickle-2.2.1\r\n",
      "  Attempting uninstall: click\r\n",
      "    Found existing installation: click 8.1.7\r\n",
      "    Uninstalling click-8.1.7:\r\n",
      "      Successfully uninstalled click-8.1.7\r\n",
      "  Attempting uninstall: charset-normalizer\r\n",
      "    Found existing installation: charset-normalizer 3.3.2\r\n",
      "    Uninstalling charset-normalizer-3.3.2:\r\n",
      "      Successfully uninstalled charset-normalizer-3.3.2\r\n",
      "  Attempting uninstall: certifi\r\n",
      "    Found existing installation: certifi 2023.11.17\r\n",
      "    Uninstalling certifi-2023.11.17:\r\n",
      "      Successfully uninstalled certifi-2023.11.17\r\n",
      "  Attempting uninstall: attrs\r\n",
      "    Found existing installation: attrs 23.2.0\r\n",
      "    Uninstalling attrs-23.2.0:\r\n",
      "      Successfully uninstalled attrs-23.2.0\r\n",
      "  Attempting uninstall: async-timeout\r\n",
      "    Found existing installation: async-timeout 4.0.3\r\n",
      "    Uninstalling async-timeout-4.0.3:\r\n",
      "      Successfully uninstalled async-timeout-4.0.3\r\n",
      "  Attempting uninstall: appnope\r\n",
      "    Found existing installation: appnope 0.1.3\r\n",
      "    Uninstalling appnope-0.1.3:\r\n",
      "      Successfully uninstalled appnope-0.1.3\r\n",
      "  Attempting uninstall: absl-py\r\n",
      "    Found existing installation: absl-py 2.0.0\r\n",
      "    Uninstalling absl-py-2.0.0:\r\n",
      "      Successfully uninstalled absl-py-2.0.0\r\n",
      "  Attempting uninstall: yarl\r\n",
      "    Found existing installation: yarl 1.9.4\r\n",
      "    Uninstalling yarl-1.9.4:\r\n",
      "      Successfully uninstalled yarl-1.9.4\r\n",
      "  Attempting uninstall: scipy\r\n",
      "    Found existing installation: scipy 1.11.4\r\n",
      "    Uninstalling scipy-1.11.4:\r\n",
      "      Successfully uninstalled scipy-1.11.4\r\n",
      "  Attempting uninstall: schema\r\n",
      "    Found existing installation: schema 0.7.5\r\n",
      "    Uninstalling schema-0.7.5:\r\n",
      "      Successfully uninstalled schema-0.7.5\r\n",
      "  Attempting uninstall: requests\r\n",
      "    Found existing installation: requests 2.31.0\r\n",
      "    Uninstalling requests-2.31.0:\r\n",
      "      Successfully uninstalled requests-2.31.0\r\n",
      "  Attempting uninstall: referencing\r\n",
      "    Found existing installation: referencing 0.32.1\r\n",
      "    Uninstalling referencing-0.32.1:\r\n",
      "      Successfully uninstalled referencing-0.32.1\r\n",
      "  Attempting uninstall: python-dateutil\r\n",
      "    Found existing installation: python-dateutil 2.8.2\r\n",
      "    Uninstalling python-dateutil-2.8.2:\r\n",
      "      Successfully uninstalled python-dateutil-2.8.2\r\n",
      "  Attempting uninstall: pyfunctional\r\n",
      "    Found existing installation: pyfunctional 1.4.3\r\n",
      "    Uninstalling pyfunctional-1.4.3:\r\n",
      "      Successfully uninstalled pyfunctional-1.4.3\r\n",
      "  Attempting uninstall: pyarrow\r\n",
      "    Found existing installation: pyarrow 14.0.2\r\n",
      "    Uninstalling pyarrow-14.0.2:\r\n",
      "      Successfully uninstalled pyarrow-14.0.2\r\n",
      "  Attempting uninstall: nltk\r\n",
      "    Found existing installation: nltk 3.8.1\r\n",
      "    Uninstalling nltk-3.8.1:\r\n",
      "      Successfully uninstalled nltk-3.8.1\r\n",
      "  Attempting uninstall: mypy-boto3-bedrock\r\n",
      "    Found existing installation: mypy-boto3-bedrock 1.34.0\r\n",
      "    Uninstalling mypy-boto3-bedrock-1.34.0:\r\n",
      "      Successfully uninstalled mypy-boto3-bedrock-1.34.0\r\n",
      "  Attempting uninstall: multiprocess\r\n",
      "    Found existing installation: multiprocess 0.70.15\r\n",
      "    Uninstalling multiprocess-0.70.15:\r\n",
      "      Successfully uninstalled multiprocess-0.70.15\r\n",
      "  Attempting uninstall: matplotlib-inline\r\n",
      "    Found existing installation: matplotlib-inline 0.1.6\r\n",
      "    Uninstalling matplotlib-inline-0.1.6:\r\n",
      "      Successfully uninstalled matplotlib-inline-0.1.6\r\n",
      "  Attempting uninstall: jupyter-core\r\n",
      "    Found existing installation: jupyter_core 5.7.1\r\n",
      "    Uninstalling jupyter_core-5.7.1:\r\n",
      "      Successfully uninstalled jupyter_core-5.7.1\r\n",
      "  Attempting uninstall: jiwer\r\n",
      "    Found existing installation: jiwer 3.0.3\r\n",
      "    Uninstalling jiwer-3.0.3:\r\n",
      "      Successfully uninstalled jiwer-3.0.3\r\n",
      "  Attempting uninstall: jinja2\r\n",
      "    Found existing installation: Jinja2 3.1.3\r\n",
      "    Uninstalling Jinja2-3.1.3:\r\n",
      "      Successfully uninstalled Jinja2-3.1.3\r\n",
      "  Attempting uninstall: jedi\r\n",
      "    Found existing installation: jedi 0.19.1\r\n",
      "    Uninstalling jedi-0.19.1:\r\n",
      "      Successfully uninstalled jedi-0.19.1\r\n",
      "  Attempting uninstall: importlib-metadata\r\n",
      "    Found existing installation: importlib-metadata 6.11.0\r\n",
      "    Uninstalling importlib-metadata-6.11.0:\r\n",
      "      Successfully uninstalled importlib-metadata-6.11.0\r\n",
      "  Attempting uninstall: google-pasta\r\n",
      "    Found existing installation: google-pasta 0.2.0\r\n",
      "    Uninstalling google-pasta-0.2.0:\r\n",
      "      Successfully uninstalled google-pasta-0.2.0\r\n",
      "  Attempting uninstall: contourpy\r\n",
      "    Found existing installation: contourpy 1.2.0\r\n",
      "    Uninstalling contourpy-1.2.0:\r\n",
      "      Successfully uninstalled contourpy-1.2.0\r\n",
      "  Attempting uninstall: comm\r\n",
      "    Found existing installation: comm 0.2.1\r\n",
      "    Uninstalling comm-0.2.1:\r\n",
      "      Successfully uninstalled comm-0.2.1\r\n",
      "  Attempting uninstall: asttokens\r\n",
      "    Found existing installation: asttokens 2.4.1\r\n",
      "    Uninstalling asttokens-2.4.1:\r\n",
      "      Successfully uninstalled asttokens-2.4.1\r\n",
      "  Attempting uninstall: aiosignal\r\n",
      "    Found existing installation: aiosignal 1.3.1\r\n",
      "    Uninstalling aiosignal-1.3.1:\r\n",
      "      Successfully uninstalled aiosignal-1.3.1\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.1.2\r\n",
      "    Uninstalling torch-2.1.2:\r\n",
      "      Successfully uninstalled torch-2.1.2\r\n",
      "  Attempting uninstall: stack-data\r\n",
      "    Found existing installation: stack-data 0.6.3\r\n",
      "    Uninstalling stack-data-0.6.3:\r\n",
      "      Successfully uninstalled stack-data-0.6.3\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.3.2\r\n",
      "    Uninstalling scikit-learn-1.3.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.3.2\r\n",
      "  Attempting uninstall: rouge-score\r\n",
      "    Found existing installation: rouge-score 0.1.2\r\n",
      "    Uninstalling rouge-score-0.1.2:\r\n",
      "      Successfully uninstalled rouge-score-0.1.2\r\n",
      "  Attempting uninstall: responses\r\n",
      "    Found existing installation: responses 0.18.0\r\n",
      "    Uninstalling responses-0.18.0:\r\n",
      "      Successfully uninstalled responses-0.18.0\r\n",
      "  Attempting uninstall: pathos\r\n",
      "    Found existing installation: pathos 0.3.1\r\n",
      "    Uninstalling pathos-0.3.1:\r\n",
      "      Successfully uninstalled pathos-0.3.1\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 2.1.4\r\n",
      "    Uninstalling pandas-2.1.4:\r\n",
      "      Successfully uninstalled pandas-2.1.4\r\n",
      "  Attempting uninstall: matplotlib\r\n",
      "    Found existing installation: matplotlib 3.8.2\r\n",
      "    Uninstalling matplotlib-3.8.2:\r\n",
      "      Successfully uninstalled matplotlib-3.8.2\r\n",
      "  Attempting uninstall: jupyter-client\r\n",
      "    Found existing installation: jupyter_client 8.6.0\r\n",
      "    Uninstalling jupyter_client-8.6.0:\r\n",
      "      Successfully uninstalled jupyter_client-8.6.0\r\n",
      "  Attempting uninstall: jsonschema-specifications\r\n",
      "    Found existing installation: jsonschema-specifications 2023.12.1\r\n",
      "    Uninstalling jsonschema-specifications-2023.12.1:\r\n",
      "      Successfully uninstalled jsonschema-specifications-2023.12.1\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.20.2\r\n",
      "    Uninstalling huggingface-hub-0.20.2:\r\n",
      "      Successfully uninstalled huggingface-hub-0.20.2\r\n",
      "  Attempting uninstall: docker\r\n",
      "    Found existing installation: docker 7.0.0\r\n",
      "    Uninstalling docker-7.0.0:\r\n",
      "      Successfully uninstalled docker-7.0.0\r\n",
      "  Attempting uninstall: botocore\r\n",
      "    Found existing installation: botocore 1.33.13\r\n",
      "    Uninstalling botocore-1.33.13:\r\n",
      "      Successfully uninstalled botocore-1.33.13\r\n",
      "  Attempting uninstall: aiohttp\r\n",
      "    Found existing installation: aiohttp 3.9.1\r\n",
      "    Uninstalling aiohttp-3.9.1:\r\n",
      "      Successfully uninstalled aiohttp-3.9.1\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.22.1\r\n",
      "    Uninstalling transformers-4.22.1:\r\n",
      "      Successfully uninstalled transformers-4.22.1\r\n",
      "  Attempting uninstall: s3transfer\r\n",
      "    Found existing installation: s3transfer 0.10.0\r\n",
      "    Uninstalling s3transfer-0.10.0:\r\n",
      "      Successfully uninstalled s3transfer-0.10.0\r\n",
      "  Attempting uninstall: jsonschema\r\n",
      "    Found existing installation: jsonschema 4.20.0\r\n",
      "    Uninstalling jsonschema-4.20.0:\r\n",
      "      Successfully uninstalled jsonschema-4.20.0\r\n",
      "  Attempting uninstall: IPython\r\n",
      "    Found existing installation: ipython 8.20.0\r\n",
      "    Uninstalling ipython-8.20.0:\r\n",
      "      Successfully uninstalled ipython-8.20.0\r\n",
      "  Attempting uninstall: ray\r\n",
      "    Found existing installation: ray 2.7.1\r\n",
      "    Uninstalling ray-2.7.1:\r\n",
      "      Successfully uninstalled ray-2.7.1\r\n",
      "  Attempting uninstall: nbformat\r\n",
      "    Found existing installation: nbformat 5.9.2\r\n",
      "    Uninstalling nbformat-5.9.2:\r\n",
      "      Successfully uninstalled nbformat-5.9.2\r\n",
      "  Attempting uninstall: ipykernel\r\n",
      "    Found existing installation: ipykernel 6.28.0\r\n",
      "    Uninstalling ipykernel-6.28.0:\r\n",
      "      Successfully uninstalled ipykernel-6.28.0\r\n",
      "  Attempting uninstall: detoxify\r\n",
      "    Found existing installation: detoxify 0.5.1\r\n",
      "    Uninstalling detoxify-0.5.1:\r\n",
      "      Successfully uninstalled detoxify-0.5.1\r\n",
      "  Attempting uninstall: datasets\r\n",
      "    Found existing installation: datasets 2.16.1\r\n",
      "    Uninstalling datasets-2.16.1:\r\n",
      "      Successfully uninstalled datasets-2.16.1\r\n",
      "  Attempting uninstall: boto3\r\n",
      "    Found existing installation: boto3 1.34.19\r\n",
      "    Uninstalling boto3-1.34.19:\r\n",
      "      Successfully uninstalled boto3-1.34.19\r\n",
      "  Attempting uninstall: bert-score\r\n",
      "    Found existing installation: bert-score 0.3.13\r\n",
      "    Uninstalling bert-score-0.3.13:\r\n",
      "      Successfully uninstalled bert-score-0.3.13\r\n",
      "  Attempting uninstall: sagemaker\r\n",
      "    Found existing installation: sagemaker 2.203.1\r\n",
      "    Uninstalling sagemaker-2.203.1:\r\n",
      "      Successfully uninstalled sagemaker-2.203.1\r\n",
      "  Attempting uninstall: nbclient\r\n",
      "    Found existing installation: nbclient 0.9.0\r\n",
      "    Uninstalling nbclient-0.9.0:\r\n",
      "      Successfully uninstalled nbclient-0.9.0\r\n",
      "  Attempting uninstall: evaluate\r\n",
      "    Found existing installation: evaluate 0.4.1\r\n",
      "    Uninstalling evaluate-0.4.1:\r\n",
      "      Successfully uninstalled evaluate-0.4.1\r\n",
      "  Attempting uninstall: testbook\r\n",
      "    Found existing installation: testbook 0.4.2\r\n",
      "    Uninstalling testbook-0.4.2:\r\n",
      "      Successfully uninstalled testbook-0.4.2\r\n",
      "  Attempting uninstall: fmeval\r\n",
      "    Found existing installation: fmeval 0.3.0\r\n",
      "    Uninstalling fmeval-0.3.0:\r\n",
      "      Successfully uninstalled fmeval-0.3.0\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "aiobotocore 2.9.0 requires botocore<1.33.14,>=1.33.2, but you have botocore 1.34.36 which is incompatible.\r\n",
      "awscli 1.32.19 requires botocore==1.34.19, but you have botocore 1.34.36 which is incompatible.\r\n",
      "s3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed IPython-8.21.0 MarkupSafe-2.1.5 absl-py-2.1.0 aiohttp-3.9.3 aiosignal-1.3.1 appnope-0.1.4 asttokens-2.4.1 async-timeout-4.0.3 attrs-23.2.0 bert-score-0.3.13 boto3-1.34.36 botocore-1.34.36 certifi-2024.2.2 charset-normalizer-3.3.2 click-8.1.7 cloudpickle-2.2.1 comm-0.2.1 contextlib2-21.6.0 contourpy-1.2.0 cycler-0.12.1 datasets-2.16.1 debugpy-1.8.0 decorator-5.1.1 detoxify-0.5.2 dill-0.3.7 docker-7.0.0 evaluate-0.4.1 exceptiongroup-1.2.0 executing-2.0.1 fastjsonschema-2.19.1 filelock-3.13.1 fmeval-0.3.0 fonttools-4.48.1 frozenlist-1.4.1 fsspec-2023.10.0 google-pasta-0.2.0 huggingface-hub-0.20.3 idna-3.6 importlib-metadata-6.11.0 ipykernel-6.29.2 jedi-0.19.1 jinja2-3.1.3 jiwer-3.0.3 jmespath-1.0.1 joblib-1.3.2 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 jupyter-client-8.6.0 jupyter-core-5.7.1 kiwisolver-1.4.5 markdown-3.5.2 matplotlib-3.8.2 matplotlib-inline-0.1.6 mpmath-1.3.0 msgpack-1.0.7 multidict-6.0.5 multiprocess-0.70.15 mypy-boto3-bedrock-1.34.0 nbclient-0.9.0 nbformat-5.9.2 nest-asyncio-1.6.0 networkx-3.2.1 nltk-3.8.1 numpy-1.26.4 packaging-23.2 pandas-2.2.0 parso-0.8.3 pathos-0.3.1 pexpect-4.9.0 pillow-10.2.0 platformdirs-4.2.0 pox-0.3.4 ppft-1.7.6.8 prompt-toolkit-3.0.43 protobuf-4.25.2 psutil-5.9.8 ptyprocess-0.7.0 pure-eval-0.2.2 pyarrow-15.0.0 pyarrow-hotfix-0.6 pyfunctional-1.4.3 pygments-2.17.2 pyparsing-3.1.1 python-dateutil-2.8.2 pytz-2024.1 pyyaml-6.0.1 pyzmq-25.1.2 rapidfuzz-3.6.1 ray-2.7.1 referencing-0.33.0 regex-2023.12.25 requests-2.31.0 responses-0.18.0 rouge-score-0.1.2 rpds-py-0.17.1 s3transfer-0.10.0 sagemaker-2.207.1 schema-0.7.5 scikit-learn-1.4.0 scipy-1.12.0 semantic-version-2.10.0 sentencepiece-0.1.99 six-1.16.0 smdebug-rulesconfig-1.0.1 stack-data-0.6.3 sympy-1.12 tabulate-0.9.0 tblib-2.0.0 testbook-0.4.2 threadpoolctl-3.2.0 tokenizers-0.12.1 torch-2.2.0 tornado-6.4 tqdm-4.66.1 traitlets-5.14.1 transformers-4.22.1 typing-extensions-4.9.0 tzdata-2023.4 urllib3-1.26.18 wcwidth-0.2.13 xxhash-3.4.1 yarl-1.9.4 zipp-3.17.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install fmeval==0.3.0\n",
    "!pip3 install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76487ff0709f4921",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.function_step import step\n",
    "from steps.deploy_llama7b import deploy_llama7b\n",
    "from steps.finetune_llama7b import finetune_llama7b\n",
    "from steps.deploy_finetuned_llama7b import deploy_finetuned_llama7b\n",
    "from steps.selection import selection\n",
    "from steps.preprocess import preprocess\n",
    "from steps.evaluation import evaluation\n",
    "from steps.register import register\n",
    "from steps.cleanup import cleanup\n",
    "from steps.utils import create_training_job_name\n",
    "import os\n",
    "\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d5f58-65e2-4d01-8303-8a2d420e09bf",
   "metadata": {},
   "source": [
    "### Evaluation dataset preparation - preprocess step\n",
    "We save data paths of the evaluation dataset in *evaluation_data_path* and the path for the pipeline outputs in *output_data_path*.  \n",
    "We then configure **preprocess** our first pipeline step. This step will take care of any data preprocessing that must be done\n",
    "on the evaluation dataset. The output data path after processing is contained in *preprocess_step_ret*.  \n",
    "Remember the *pipeline_name* as it will be used also in SageMaker Studio to identify our pipeline.  \n",
    "Also mark down the path of the S3 bucket used as output for later consultation.\n",
    "\n",
    "For running this example we will use a sub sample taken from [SCIQ](https://huggingface.co/datasets/sciq) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538466bfbdc3e26",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_name = \"genai-for-builders-fmops-pipeline\"\n",
    "\n",
    "default_bucket = sagemaker.Session().default_bucket()\n",
    "main_data_path = f\"s3://{default_bucket}\"\n",
    "evaluation_data_path= main_data_path + \"/datasets/sciq/evaluation/automatic/dataset_evaluation.jsonl\"\n",
    "output_data_path = (main_data_path + \"/datasets/sciq/output_\" + pipeline_name)\n",
    "\n",
    "# You can add your own evaluation dataset code into this step\n",
    "preprocess_step_ret = step(preprocess, name=\"preprocess\")(evaluation_data_path, output_data_path)\n",
    "\n",
    "print(\"The pipeline name is \"+pipeline_name)\n",
    "# Mark the name of this bucket for reviewing the artifacts generated by this pipeline at the end of the execution\n",
    "print(\"Output S3 bucket: \"+output_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd50b41df5a91de",
   "metadata": {},
   "source": [
    "### Setup models\n",
    "We are now going to add different models into pipeline. Each model will have an optional **finetune** step, a **deploy** step and finally an **evaluation** step.\n",
    "Before starting the setup we instantiate a couple of supporting array. \n",
    "*model_list* will contain the list of models defined as a dictionary of parameters.  \n",
    "*evaluation_results_ret_list* will contain the result of the evaluation generated by the **evaluation** step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_list = []\n",
    "evaluation_results_ret_list = []"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d814fa1c33fb23f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup first model: LLama-2-7b from SageMaker Jumpstart\n",
    "For the first model we are using LLama-2-7b available in Amazon SageMaker Jumpstart.\n",
    "We collect all the required parameters into a dictionary and we add it to *model_list* for later use.  \n",
    "We will use one *ml.g5.2xlarge* instance for inference."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbaf64feaf794296"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0838a5d8ab07589",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We setup required model parameters\n",
    "model_1 = {\"model_id\": \"meta-textgeneration-llama-2-7b\",\n",
    "           \"model_version\": \"3.0.2\",\n",
    "           \"model_name\": \"llama-2-7b\",\n",
    "           \"endpoint_name\": \"genai-for-builders-fmops-meta-textgeneration-llama-2-7b\",\n",
    "           \"instance_type\": \"ml.g5.2xlarge\",\n",
    "           \"num_instances\": 1}\n",
    "\n",
    "# We save the information of the model in the model_list array for later use\n",
    "model_list.append(model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ec385385fae3",
   "metadata": {},
   "source": [
    "We then configure **deploy** and **evaluation** data step. Note that **evaluation** step is dependent on both **preprocess** and **deploy** steps because is using the ret values as step inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f73ce22a54ef8f",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "deploy_llama7b_ret = step(deploy_llama7b, name=\"deploy_llama7b\")(model_1)\n",
    "\n",
    "# Evaluation step is using the output from preprocess (the S3 location of the evaluation dataset file) \n",
    "# and the output of the deploy step (the endpoint name)\n",
    "evaluate_llama7b_ret = step(evaluation,\n",
    "                    name=\"evaluate_llama7b\",\n",
    "                    keep_alive_period_in_seconds=1200\n",
    "                    )(model_1,\n",
    "                      preprocess_step_ret,\n",
    "                      deploy_llama7b_ret)\n",
    "\n",
    "# We save the evaluation output details in the evaluation_results_ret_list array for later use\n",
    "evaluation_results_ret_list.append(evaluate_llama7b_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff5ba2f26142490",
   "metadata": {},
   "source": [
    "### Setup second model: LLama-2-7b from SageMaker Jumpstart to be instruction finetuned\n",
    "The second model in this example is a LLama-2-7b from SageMaker Jumpstart that we are going to finetune with an instruction dataset.  \n",
    "For this model we are going to set parameters required for finetuning job such as:\n",
    "- *finetune_instance_type*: the instance type that will be used to finetune the model\n",
    "- *epoch*: number of finetune epochs\n",
    "- *max_input_length*: maximum input sequence length\n",
    "- *per_device_train_batch_size*: batch size per device\n",
    "- *instruction_tuned*: set to True will force the model to be instruction tuned\n",
    "- *training_data_path*: the S3 data path containing the training dataset\n",
    "\n",
    "We also setup the training job name manually to track it down during the pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464f2b32af0481d0",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-08T11:43:07.403523Z",
     "start_time": "2024-02-08T11:43:05.475614Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'default_bucket' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 16\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# We setup required model parameters\u001B[39;00m\n\u001B[1;32m      2\u001B[0m model_2 \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmeta-textgeneration-llama-2-7b\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_version\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m3.0.2\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllama-2-7b-instruction-tuned\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mendpoint_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenai-for-builders-fmops-meta-llama-2-7b-instr-finetuned\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfinetune_instance_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mml.g5.12xlarge\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfinetune_num_instances\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minstance_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mml.g5.2xlarge\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_instances\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_input_length\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m512\u001B[39m,\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mper_device_train_batch_size\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m4\u001B[39m,\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minstruction_tuned\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrue\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchat_dataset\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFalse\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m---> 16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining_data_path\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ms3://\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mdefault_bucket\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/datasets/sciq/fine_tuning/instruction_fine_tuning\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_finetuned_model\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     18\u001B[0m }\n\u001B[1;32m     19\u001B[0m model_2[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining_job_name\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m create_training_job_name(model_2[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_id\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# We save the information of the model in the model_list array for later use\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'default_bucket' is not defined"
     ]
    }
   ],
   "source": [
    "# We setup required model parameters\n",
    "model_2 = {\n",
    "    \"model_id\": \"meta-textgeneration-llama-2-7b\",\n",
    "    \"model_version\": \"3.0.2\",\n",
    "    \"model_name\": \"llama-2-7b-instruction-tuned\",\n",
    "    \"endpoint_name\": \"genai-for-builders-fmops-meta-llama-2-7b-instr-finetuned\",\n",
    "    \"finetune_instance_type\": \"ml.g5.12xlarge\",\n",
    "    \"finetune_num_instances\": 1,\n",
    "    \"instance_type\": \"ml.g5.2xlarge\",\n",
    "    \"num_instances\": 1,\n",
    "    \"epoch\": 1,\n",
    "    \"max_input_length\": 512,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"instruction_tuned\": \"True\",\n",
    "    \"chat_dataset\": \"False\",\n",
    "    \"training_data_path\": f\"s3://{default_bucket}/datasets/sciq/fine_tuning/instruction_fine_tuning\",\n",
    "    \"is_finetuned_model\": True\n",
    "}\n",
    "model_2[\"training_job_name\"] = create_training_job_name(model_2[\"model_id\"])\n",
    "\n",
    "# We save the information of the model in the model_list array for later use\n",
    "model_list.append(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b715608d4b4ad1",
   "metadata": {},
   "source": [
    "We are now going to create the pipeline steps for the second model. For model 2 we add a **finetune** step before the **deploy** and **evaluation** steps.  \n",
    "As before we are saving the evaluation results into *evaluation_results_ret_list* array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa484035f7f5a4",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_ret = step(finetune_llama7b, name=\"finetune_llama7b_instruction\")(model_2)\n",
    "\n",
    "# Deploy step is using the output from the finetune step (the training job name)\n",
    "deploy_finetuned_llama7b_ret = step(deploy_finetuned_llama7b, \n",
    "                                    name=\"deploy_finetuned_llama7b_instruction\")(model_2, finetune_ret)\n",
    "\n",
    "# Evaluation step is using the output from preprocess (the S3 location of the evaluation dataset file) \n",
    "# and the output of the deploy step (the endpoint name)\n",
    "evaluate_finetuned_llama7b_instruction_ret = step(evaluation,\n",
    "                    name=\"evaluate_finetuned_llama7b_instr\",\n",
    "                    keep_alive_period_in_seconds=1200,\n",
    "                    )(model_2,\n",
    "                      preprocess_step_ret,\n",
    "                      deploy_finetuned_llama7b_ret)\n",
    "\n",
    "# We save the information of the model in the model_list array for later use\n",
    "evaluation_results_ret_list.append(evaluate_finetuned_llama7b_instruction_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup third model: LLama-2-7b-chat from SageMaker Jumpstart to be domain finetuned\n",
    "The third model in this example is a LLama-2-7b-chat from SageMaker Jumpstart that we are going to finetune\n",
    "with a domain dataset.  \n",
    "For this model we are going to set parameters required for finetuning job such as:\n",
    "- *finetune_instance_type*: the instance type that will be used to finetune the model\n",
    "- *epoch*: number of finetune epochs\n",
    "- *max_input_length*: maximum input sequence length\n",
    "- *instruction_tuned*: set to True will force the model to be instruction tuned\n",
    "- *training_data_path*: the S3 data path containing the training dataset\n",
    "- *per_device_train_batch_size*: batch size per device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5425f135245e0944"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We setup required model parameters\n",
    "model_3 = {\n",
    "    \"model_id\": \"meta-textgeneration-llama-2-7b-f\",\n",
    "    \"model_version\": \"3.0.2\",\n",
    "    \"model_name\": \"llama-2-7b-chat-domain-tuned\",\n",
    "    \"endpoint_name\": \"genai-for-builders-fmops-meta-llama-2-7b-chat-dom-finetuned\",\n",
    "    \"finetune_instance_type\": \"ml.g5.12xlarge\",\n",
    "    \"finetune_num_instances\": 1,\n",
    "    \"instance_type\": \"ml.g5.2xlarge\",\n",
    "    \"num_instances\": 1,\n",
    "    \"epoch\": 5,\n",
    "    \"max_input_length\": 512,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"instruction_tuned\": \"False\",\n",
    "    \"chat_dataset\": \"False\",\n",
    "    \"training_data_path\": f\"s3://{default_bucket}/datasets/sciq/fine_tuning/domain_adaptation_fine_tuning\",\n",
    "    \"is_finetuned_model\": True\n",
    "}\n",
    "model_3[\"training_job_name\"] = create_training_job_name(model_3[\"model_id\"])\n",
    "\n",
    "# We save the information of the model in the model_list array for later use\n",
    "model_list.append(model_3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca692e551ee74f31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are now going to create the pipeline steps for model 3 like we did for model 2."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18801dd08ba069f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "domain_finetune_ret = step(finetune_llama7b, name=\"finetune_llama7b_domain\")(model_3)\n",
    "\n",
    "# Deploy step is using the output from the finetune step (the training job name)\n",
    "deploy_finetuned_llama7b_dom_ret = step(deploy_finetuned_llama7b, \n",
    "                                    name=\"deploy_finetuned_llama7b_domain\")(model_3, domain_finetune_ret)\n",
    "\n",
    "# Evaluation step is using the output from preprocess (the S3 location of the evaluation dataset file) \n",
    "# and the output of the deploy step (the endpoint name)\n",
    "evaluate_finetuned_llama7b_domain_ret = step(evaluation,\n",
    "                    name=\"evaluate_finetuned_llama7b_dom\",\n",
    "                    keep_alive_period_in_seconds=1200,\n",
    "                    )(model_3,\n",
    "                      preprocess_step_ret,\n",
    "                      deploy_finetuned_llama7b_dom_ret)\n",
    "\n",
    "# We save the information of the model in the model_list array for later use\n",
    "evaluation_results_ret_list.append(evaluate_finetuned_llama7b_domain_ret)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "336a4b0cf9ab3f0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Select best model and register it in SageMaker Model Registry\n",
    "Now it's time to select best model. To do so we create a pipeline step dedicated to the best model **selection**.\n",
    "The selection is using the output of all the models' evaluation.\n",
    "The output of the **selection** step is the best model name. We will use the best model name in the **register** step.  \n",
    "The **register** step will also need a package group and description name."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48f23d56614aea50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluation step is using the output from the evaluation steps of all the models\n",
    "selection_ret = step(selection, name=\"best_model_selection\")(*evaluation_results_ret_list)\n",
    "\n",
    "# Set a package group name and description\n",
    "model_package_group_name = \"GenAIForBuilderFMOpsEvaluationPipeline\"\n",
    "model_package_group_description = \"GenAI For Builder FMOps Evaluation Pipeline Model Registry\"\n",
    "\n",
    "# We will register the best model in the model register. The best model name is contained in the return object of the selection step\n",
    "register_ret = step(register, name=\"best_model_register\")(model_list,\n",
    "                                                          output_data_path,\n",
    "                                                          model_package_group_name,\n",
    "                                                          model_package_group_description,\n",
    "                                                          selection_ret,\n",
    "                                                          *evaluation_results_ret_list)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b05c18a5295ce0a"
  },
  {
   "cell_type": "markdown",
   "id": "478f53e262aafb7c",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "The last pipeline step is dedicated to cleanup all the resource that we are going to instantiate with the pipeline.\n",
    "For each model we create a **cleanup** step to be executed in parallel. All **cleanup** steps will fan-out after **register** step as they are dependent on its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71735d24ab99ad89",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We need to create a cleanup step for each model. We collect the return objects to add them later in the pipeline creation function\n",
    "cleanup_ret_list = []\n",
    "\n",
    "for model in model_list:\n",
    "    # We append register_ret to connect the register and cleanup steps together\n",
    "    cleanup_ret = step(cleanup, name=\"cleanup_\"+model[\"model_name\"])(model[\"endpoint_name\"], register_ret)\n",
    "    cleanup_ret_list.append(cleanup_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce0babb-70c2-4b2b-bde8-f0986109fde6",
   "metadata": {},
   "source": [
    "### Creating and launching the pipeline\n",
    "We are finally ready to create and launch the pipeline but before doing that we will need to create a requirements.txt file.\n",
    "As a best practice we are reading the current sagemaker library version that we are using to create the pipeline and set it as a requirement into the requirement file.\n",
    "Keeping the same sagemaker version in the creation and running phase will allow us to avoid any deserialization issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c682ddc-f4fc-4ef4-8081-d753032f2888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"requirements.txt\"):\n",
    "    os.remove(\"requirements.txt\")\n",
    "\n",
    "with open('requirements.txt', 'w') as req_file:\n",
    "    req_file.write(\"fmeval==0.3.0\\n\")\n",
    "    req_file.write(\"sagemaker==\" + str(sagemaker.__version__) + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5abfcc508e191",
   "metadata": {},
   "source": [
    "In the last cell of this notebook we are creating the pipeline and serializing it to S3. \n",
    "Don't forget to attach the execution role with sufficient permission and the return results from the last steps of our pipeline.\n",
    "We are now ready to start the pipeline execution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "pipeline = Pipeline(name=pipeline_name, steps=cleanup_ret_list)\n",
    "pipeline.upsert(role)\n",
    "pipeline.start()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8f091649f823362"
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
