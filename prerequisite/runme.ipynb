{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6496bcb-59a1-4041-bf86-0a19df0a6765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f1b962-791e-42d3-af83-9187a2a62ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from datasets import disable_caching\n",
    "\n",
    "import boto3\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "\n",
    "dataset_loaded_sciq = False\n",
    "dataset_loaded_squad = False\n",
    "\n",
    "# creating some dummy value for the dataset global variable\n",
    "dataset = { 'train': [\"a\", \"b\"], 'test':[\"a\", \"b\"]}\n",
    "\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd2cea-16a0-4114-a849-6d4cf31081ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_dashes():\n",
    "    print('-'.join('' for x in range(100)))\n",
    "\n",
    "def translate_to_text(data, column_name=\"context\"):\n",
    "    data_pd = pd.DataFrame(data)\n",
    "    return \" \\n\".join(((data_pd.drop_duplicates(subset=[column_name]))[column_name]))\n",
    "\n",
    "def safe_open_w(path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    return open(path, 'w')\n",
    "\n",
    "def write_to_file(input_str, file_path):\n",
    "    with safe_open_w(file_path) as text_file:\n",
    "        text_file.write(input_str)\n",
    "\n",
    "def create_custom_template(template, file_path):\n",
    "    with safe_open_w(file_path) as text_file:\n",
    "        json.dump(template, text_file)\n",
    "    return template\n",
    "\n",
    "def attach_cors_to_bucket(bucket_name):    \n",
    "    s3 = boto3.client('s3')\n",
    "  \n",
    "    try:\n",
    "        response = s3.put_bucket_cors(Bucket = bucket_name, \n",
    "                                      CORSConfiguration = {\n",
    "                                            'CORSRules' : [\n",
    "                                                {\n",
    "                                                    'ID' : bucket_name + 'cors',\n",
    "                                                    'AllowedHeaders' : [ '*' ],\n",
    "                                                    'AllowedMethods' : [ 'PUT', 'GET', 'POST', 'DELETE', 'HEAD' ],\n",
    "                                                    'AllowedOrigins' : [ '*' ],\n",
    "                                                    'ExposeHeaders' :  [ 'ETag', 'x-amz-delete-marker', 'x-amz-server-side-encryption',\n",
    "                                                                         'x-amz-request-id','x-amz-version-id','x-amz-id-2']\n",
    "                                                }\n",
    "                                            ]\n",
    "                                        })\n",
    "    except ClientError as e:\n",
    "            return None\n",
    "    return response\n",
    "\n",
    "def upload_workshop_dataset(dataset_name,\n",
    "                            output_bucket = sagemaker.Session().default_bucket(),\n",
    "                            local_path = \".\"):\n",
    "    \n",
    "    attach_cors_to_bucket(output_bucket) # requirment by Studio UI\n",
    "    \n",
    "    output_s3_path =  output_bucket + \"/datasets\" \n",
    "    \n",
    "    data_location = f\"s3://{output_s3_path}/\" + dataset_name\n",
    "    \n",
    "    fine_tune_data_ist_location = f\"{data_location}/fine_tuning/instruction_fine_tuning\"\n",
    "    fine_tune_data_daft_location = f\"{data_location}/fine_tuning/domain_adaptation_fine_tuning\"\n",
    "    evaluation_data_location = f\"{data_location}/evaluation/automatic\"\n",
    "    evaluation_data_small_location = f\"{data_location}/evaluation/automatic_small\"\n",
    "    evaluation_data_hil_location = f\"{data_location}/evaluation/hil\"\n",
    "    \n",
    "    if(os.path.isfile(f\"{local_path}/template.json\")):\n",
    "        print(\"Uploading custom template...\")\n",
    "        S3Uploader.upload(f\"{local_path}/template.json\", fine_tune_data_ist_location)\n",
    "        print(\"Done\")\n",
    "    \n",
    "    if(os.path.isfile(f\"{local_path}/dataset_finetune_ist.jsonl\")):\n",
    "        print(\"Uploading instruction tuning dataset...\")\n",
    "        S3Uploader.upload(f\"{local_path}/dataset_finetune_ist.jsonl\", fine_tune_data_ist_location)\n",
    "        print(f\"Fine-tuning ist data: {fine_tune_data_ist_location}\")\n",
    "    \n",
    "    if(os.path.isfile(f\"{local_path}/dataset_finetune_daft.txt\")):\n",
    "        print(\"Uploading domain adaptation tuning dataset...\")\n",
    "        S3Uploader.upload(f\"{local_path}/dataset_finetune_daft.txt\", fine_tune_data_daft_location)\n",
    "        print(f\"Fine-tuning daft data: {fine_tune_data_daft_location}\")\n",
    "    \n",
    "    if(os.path.isfile(f\"{local_path}/dataset_evaluation.jsonl\")):\n",
    "        print(\"Uploading evaluation dataset...\")\n",
    "        S3Uploader.upload(f\"{local_path}/dataset_evaluation.jsonl\", evaluation_data_location)\n",
    "        print(f\"Evaluation data: {evaluation_data_location}\")\n",
    "    \n",
    "    if(os.path.isfile(f\"{local_path}/dataset_evaluation_small.jsonl\")):\n",
    "        print(\"Uploading small evaluation dataset...\")\n",
    "        S3Uploader.upload(f\"{local_path}/dataset_evaluation_small.jsonl\", evaluation_data_small_location)\n",
    "        print(f\"Evaluation data: {evaluation_data_small_location}\")\n",
    "        \n",
    "    if(os.path.isfile(f\"{local_path}/dataset_evaluation_hil.jsonl\")):\n",
    "        print(\"Uploading HIL evaluation dataset...\")\n",
    "        S3Uploader.upload(f\"{local_path}/dataset_evaluation_hil.jsonl\", evaluation_data_hil_location)\n",
    "        print(f\"Evaluation data: {evaluation_data_hil_location}\")\n",
    "\n",
    "def transform_dataset_hil(item):\n",
    "    return {\n",
    "        \"prompt\": {\"text\": item[\"prompt\"]},\n",
    "        \"referenceResponse\": {\"text\": item[\"referenceResponse\"]}\n",
    "    }\n",
    "\n",
    "def prepare_dataset_sciq():\n",
    "    dataset_name = 'sciq'\n",
    "\n",
    "    # required for ipython shell\n",
    "    global dataset_loaded_sciq \n",
    "    global dataset_loaded_squad \n",
    "    global dataset\n",
    "    \n",
    "    print (dataset_loaded_sciq)\n",
    "    \n",
    "    if(dataset_loaded_sciq == False):\n",
    "        dataset = load_dataset(dataset_name)\n",
    "        dataset_loaded_sciq = True\n",
    "   \n",
    "    dataset_training_df = pd.DataFrame(dataset['train'])\n",
    "    dataset_validation_df = pd.DataFrame(dataset['test'])\n",
    "    \n",
    "    number_of_raws_training = 5000 # dataset_training_df.size\n",
    "    dataset_training_df = dataset_training_df.sample(n=int(number_of_raws_training/len(dataset_training_df.columns)), random_state=42, ignore_index=True)\n",
    "    \n",
    "    #number_of_raws_validation = 2000 # dataset_training_df.size\n",
    "    #dataset_validation_df = dataset_validation_df.sample(n=int(number_of_raws_validation/len(dataset_validation_df.columns)), random_state=42, ignore_index=True)\n",
    "    \n",
    "    print_dashes()\n",
    "    print(\"Load data\")\n",
    "    print_dashes()\n",
    "    print(\"Train dataset size \" + str(dataset_training_df.size) + \" with columns\" + str(dataset_training_df.columns.to_list()) )\n",
    "    print(\"Validation dataset size \" + str(dataset_validation_df.size) + \" with columns\" + str(dataset_validation_df.columns.to_list()) )\n",
    "    print_dashes()\n",
    "    \n",
    "    print(\"\\nCreate DAFT dataset\")\n",
    "    print_dashes()\n",
    "    data_train_daft = translate_to_text(dataset_training_df, column_name='support')\n",
    "    print(\"DAFT dataset example: \" + data_train_daft[0:1000])\n",
    "    print(\"Export DAFT dataset: dataset_finetune_daft.txt\")\n",
    "    write_to_file(data_train_daft, f\"./{dataset_name}/dataset_finetune_daft.txt\")\n",
    "    print_dashes()\n",
    "    \n",
    "    print(\"\\nCreate IST dataset\")\n",
    "    print_dashes()\n",
    "    \n",
    "    include_context = False\n",
    "    \n",
    "    if include_context:\n",
    "        fields = ['support', 'question', 'correct_answer']\n",
    "        template = {\n",
    "            \"prompt\": \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{question}\\n\\n### Input:\\n{support}\",\n",
    "            \"completion\": \"{correct_answer}\"\n",
    "        }\n",
    "        \n",
    "    else:\n",
    "        fields = ['question', 'correct_answer']\n",
    "        template = {\n",
    "            \"prompt\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction: Answer this question:\\n{question}\\n\",\n",
    "            \"completion\": \"{correct_answer}\"\n",
    "        }\n",
    "        \n",
    "    dataset_train_ist_df = dataset_training_df[fields].copy()\n",
    "    print(\"IST dataframe example: \" + dataset_train_ist_df.iloc[0])\n",
    "    dataset_fine_tune_ist = Dataset.from_pandas(dataset_train_ist_df)\n",
    "    print(\"IST dataset example: \",dataset_fine_tune_ist[0])\n",
    "    print(\"Exoprt IST dataset: dataset_finetune_ist.jsonl\")\n",
    "    dataset_fine_tune_ist.to_json(f\"./{dataset_name}/dataset_finetune_ist.jsonl\",orient='records', lines=True)\n",
    "    print_dashes()\n",
    "    \n",
    "    print(\"\\nCreate prompt template and store to template.json\")\n",
    "    print_dashes()\n",
    "    print(create_custom_template(template, f\"./{dataset_name}/template.json\"))\n",
    "    print_dashes()\n",
    "    \n",
    "    print(\"\\nCreate evaluation dataset\")\n",
    "    print_dashes()\n",
    "    \n",
    "    dataset_validation_with_context_df = dataset_validation_df.copy()\n",
    "    dataset_validation_with_context_df[\"model_input\"] = \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n\" + dataset_validation_with_context_df[\"question\"] + \"\\n\\n### Input:\\n\" + dataset_validation_with_context_df[\"support\"]\n",
    "    dataset_validation_with_context_df = dataset_validation_with_context_df[['model_input','correct_answer']].copy()\n",
    "    dataset_validation_with_context_df = dataset_validation_with_context_df.rename(columns={\"correct_answer\": \"target_output\"})\n",
    "    \n",
    "    dataset_validation_no_context_df = dataset_validation_df.copy()\n",
    "    dataset_validation_no_context_df[\"model_input\"] = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction: Answer this question:\\n\"+ dataset_validation_no_context_df[\"question\"]\n",
    "    dataset_validation_no_context_df = dataset_validation_no_context_df[['model_input','correct_answer']].copy()\n",
    "    dataset_validation_no_context_df = dataset_validation_no_context_df.rename(columns={\"correct_answer\": \"target_output\"})\n",
    "    \n",
    "    if include_context:\n",
    "        print(\"Evaluation dataframe example: \" + dataset_validation_with_context_df.iloc[0])\n",
    "        dataset_evaluation = Dataset.from_pandas(dataset_validation_with_context_df)\n",
    "        print(\"Evaluation dataset example: \", dataset_evaluation[0])\n",
    "    else:\n",
    "        print(\"Evaluation dataframe example: \" + dataset_validation_no_context_df.iloc[0])\n",
    "        dataset_evaluation = Dataset.from_pandas(dataset_validation_no_context_df)\n",
    "        print(\"Evaluation dataset example: \", dataset_evaluation[0])\n",
    "    print(\"Export Evaluation dataset: dataset_evaluation.jsonl\")\n",
    "    dataset_evaluation.to_json(f\"./{dataset_name}/dataset_evaluation.jsonl\")\n",
    "    print_dashes()\n",
    "    \n",
    "    # making the evaluation_small dataset \n",
    "    print(\"\\nCreate evaluation small dataset\")\n",
    "    \n",
    "    dataset_evaluation_small_df = dataset_validation_with_context_df.head(10)\n",
    "    print(\"Evaluation dataframe small example: \" + dataset_evaluation_small_df.iloc[0])\n",
    "    dataset_evaluation_small = Dataset.from_pandas(dataset_evaluation_small_df)\n",
    "    print(\"Evaluation dataset small example: \", dataset_evaluation_small[0])\n",
    "    print(\"Export Evaluation dataset: dataset_evaluation_small.jsonl\")\n",
    "    dataset_evaluation_small.to_json(f\"./{dataset_name}/dataset_evaluation_small.jsonl\")\n",
    "    print_dashes()\n",
    "\n",
    "    # making the evaluation_hil dataset \n",
    "    print(\"\\nCreate evaluation HIL dataset\")\n",
    "    \n",
    "    dataset_evaluation_hil_df = dataset_validation_with_context_df.head(10)\n",
    "    dataset_evaluation_hil_df = dataset_evaluation_hil_df.rename(columns={\"model_input\": \"prompt\", \"target_output\": \"referenceResponse\"})\n",
    "    print(\"Evaluation dataframe hil example: \" + dataset_evaluation_hil_df.iloc[0])\n",
    "    dataset_evaluation_hil = Dataset.from_pandas(dataset_evaluation_hil_df)\n",
    "    print(\"\\nTransform evaluation HIL dataset into right format\")\n",
    "    dataset_evaluation_hil = dataset_evaluation_hil.map(transform_dataset_hil)\n",
    "    print(\"Evaluation dataset hil example: \", dataset_evaluation_hil[0])\n",
    "    print(\"Export Evaluation dataset: dataset_evaluation_hil.jsonl\")\n",
    "    dataset_evaluation_hil.to_json(f\"./{dataset_name}/dataset_evaluation_hil.jsonl\")\n",
    "    print_dashes()\n",
    "    \n",
    "    upload_workshop_dataset(dataset_name = dataset_name, output_bucket = sagemaker.Session().default_bucket(), local_path = f\"./{dataset_name}\")\n",
    "\n",
    "def prepare_dataset_squad():\n",
    "    \n",
    "    dataset_name = 'squad'\n",
    "\n",
    "    # required for ipython shell\n",
    "    global dataset_loaded_sciq \n",
    "    global dataset_loaded_squad \n",
    "    global dataset\n",
    "    \n",
    "    if(dataset_loaded_squad == False):\n",
    "        dataset = load_dataset(dataset_name)\n",
    "        dataset_loaded_squad = True\n",
    "        \n",
    "    dataset_training_df = pd.DataFrame(dataset['train'])\n",
    "    dataset_validation_df = pd.DataFrame(dataset['validation'])\n",
    "    \n",
    "    #number_of_raws_training = 5000 # dataset_training_df.size\n",
    "    #dataset_training_df = dataset_training_df.sample(n=int(number_of_raws_training/len(dataset_training_df.columns)), random_state=42, ignore_index=True)\n",
    "    \n",
    "    #number_of_raws_validation = 2000 # dataset_training_df.size\n",
    "    #dataset_validation_df = dataset_validation_df.sample(n=int(number_of_raws_validation/len(dataset_validation_df.columns)), random_state=42, ignore_index=True)\n",
    "    \n",
    "    print_dashes()\n",
    "    print(\"Load data\")\n",
    "    print_dashes()\n",
    "    print(\"Train dataset size \" + str(dataset_training_df.size) + \" with columns\" + str(dataset_training_df.columns.to_list()) )\n",
    "    print(\"Validation dataset size \" + str(dataset_validation_df.size) + \" with columns\" + str(dataset_validation_df.columns.to_list()) )\n",
    "    print_dashes()\n",
    "    \n",
    "    print(\"\\nCreate DAFT dataset\")\n",
    "    print_dashes()\n",
    "    data_train_daft = translate_to_text(dataset_training_df)\n",
    "    print(\"DAFT dataset example: \" + data_train_daft[0:1000])\n",
    "    print(\"Exoprt DAFT dataset: dataset_finetune_daft.txt\")\n",
    "    write_to_file(data_train_daft, f\"./{dataset_name}/dataset_finetune_daft.txt\")\n",
    "    print_dashes()\n",
    "    \n",
    "    print(\"\\nCreate IST dataset\")\n",
    "    print_dashes()\n",
    "    dataset_train_ist_df = dataset_training_df[['context', 'question', 'answers']].copy()\n",
    "    dataset_train_ist_df['answers'] = dataset_train_ist_df['answers'].apply(lambda x: str(x[\"text\"][0]))\n",
    "    print(\"IST dataframe example: \" + dataset_train_ist_df.iloc[0])\n",
    "    dataset_fine_tune_ist = Dataset.from_pandas(dataset_train_ist_df)\n",
    "    print(\"IST dataset example: \",dataset_fine_tune_ist[0])\n",
    "    print(\"Exoprt IST dataset: dataset_finetune_ist.jsonl\")\n",
    "    dataset_fine_tune_ist.to_json(f\"./{dataset_name}/dataset_finetune_ist.jsonl\")\n",
    "    print_dashes()\n",
    "    \n",
    "    print(\"\\nCreate prompt template and store to template.json\")\n",
    "    print_dashes()\n",
    "    template = {\n",
    "          \"prompt\": \"Given the following context: {context}\\n\\nCould you answer this question: {question} \",\n",
    "          \"completion\": \"{answers}\"\n",
    "        }\n",
    "    print(create_custom_template(template, f\"./{dataset_name}/template.json\"))\n",
    "    print_dashes()\n",
    "    \n",
    "    print(\"\\nCreate evaluation dataset\")\n",
    "    print_dashes()\n",
    "    dataset_validation_df[\"model_input\"] = \"Given the following context:\" + dataset_validation_df[\"context\"] + \"\\n\\nCould you answer this question: \" + dataset_validation_df[\"question\"]\n",
    "    dataset_evaluation_df = dataset_validation_df[['model_input','answers']].copy()\n",
    "    dataset_evaluation_df['answers'] = dataset_evaluation_df['answers'].apply(lambda x: str(' <OR> '.join(data for data in x[\"text\"])))\n",
    "    dataset_evaluation_df = dataset_evaluation_df.rename(columns={\"answers\": \"target_output\"})\n",
    "    print(\"Evaluation dataframe example: \" + dataset_evaluation_df.iloc[0])\n",
    "    dataset_evaluation = Dataset.from_pandas(dataset_evaluation_df)\n",
    "    print(\"Evaluation dataset example: \", dataset_evaluation[0])\n",
    "    print(\"Exoprt Evaluation dataset: dataset_evaluation.jsonl\")\n",
    "    dataset_evaluation.to_json(f\"./{dataset_name}/dataset_evaluation.jsonl\")\n",
    "    print_dashes()\n",
    "\n",
    "    print(\"\\nCreate evaluation small dataset\")\n",
    "    dataset_evaluation_small_df = dataset_evaluation_df.head(10)\n",
    "    print(\"Evaluation dataframe small example: \" + dataset_evaluation_small_df.iloc[0])\n",
    "    dataset_evaluation_small = Dataset.from_pandas(dataset_evaluation_small_df)\n",
    "    print(\"Evaluation dataset small example: \", dataset_evaluation_small[0])\n",
    "    print(\"Export Evaluation dataset: dataset_evaluation_small.jsonl\")\n",
    "    dataset_evaluation_small.to_json(f\"./{dataset_name}/dataset_evaluation_small.jsonl\")\n",
    "    print_dashes()\n",
    "\n",
    "    # making the evaluation_hil dataset \n",
    "    print(\"\\nCreate evaluation HIL dataset\")\n",
    "    \n",
    "    dataset_evaluation_hil_df = dataset_evaluation_df.head(10)\n",
    "    dataset_evaluation_hil_df = dataset_evaluation_hil_df.rename(columns={\"model_input\": \"prompt\", \"target_output\": \"referenceResponse\"})\n",
    "    print(\"Evaluation dataframe hil example: \" + dataset_evaluation_hil_df.iloc[0])\n",
    "    dataset_evaluation_hil = Dataset.from_pandas(dataset_evaluation_hil_df)\n",
    "    print(\"\\nTransform evaluation HIL dataset into right format\")\n",
    "    dataset_evaluation_hil = dataset_evaluation_hil.map(transform_dataset_hil)\n",
    "    print(\"Evaluation dataset hil example: \", dataset_evaluation_hil[0])\n",
    "    print(\"Export Evaluation dataset: dataset_evaluation_hil.jsonl\")\n",
    "    dataset_evaluation_hil.to_json(f\"./{dataset_name}/dataset_evaluation_hil.jsonl\")\n",
    "    print_dashes()\n",
    "    \n",
    "    upload_workshop_dataset(dataset_name = dataset_name, output_bucket = sagemaker.Session().default_bucket(), local_path = f\"./{dataset_name}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    prepare_dataset_sciq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8cf27b-a3a1-4612-8e0f-31ab98970295",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da13a92d-89ed-4624-8196-5e98aeebe1e5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
